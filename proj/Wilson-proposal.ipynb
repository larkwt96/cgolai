{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucas Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem Definition\n",
    "I'm going to investigate how well a neural net can understand the board of Conway's Game of Life.\n",
    "* The Problem:\n",
    "    * The rules of GOL will be fairly standard. There is an nxm board with cells. A cell's next state is determined by the number of alive, neighboring cells. 0,1 dies; 2,3 stays alive; 3 resurrects; 4+ kills. The initial state is generated randomly (or constructed).\n",
    "    * To measure \"how well it knows the board\", it has the ability to change a square (or maybe more than one) before the next generation is processed. This could involve resurrecting squares or killing them (swapping their current value). Through reinforcement learning, it will learn to control the state of the board.\n",
    "    * The state is the board and the possible actions is which square to swap (if any).\n",
    "* The Problem Data:\n",
    "    * The data I will use will be data generated by the GOL engine (which since it's simple, I will write).\n",
    "* The Problem Questions:\n",
    "    * I will investigate if it's possible to foster any sort of control over the system. Population regulation or keeping the cells away from the edges of the board.\n",
    "    * Can the agent prevent the cells from touching the walls?\n",
    "    * Can the agent optimize the number of cells alive?\n",
    "    * Variables: Agent can swap single cells or it can swap any cell in the board.\n",
    "\n",
    "### The AI Algorithm\n",
    "* The AI algorithms I will use is a reinforcement Q learning model with a neural network as the Q function.\n",
    "* The questions I will investigate are how well reinforcement learning can learn to control a very complex system similar to cellular automation.\n",
    "    * I will have to write code to implement a reinforcement learning agent.\n",
    "    * I will also have to define what a good reinforcement is. Since there is no objective in GOL, this is something I get to define and investigate.\n",
    "    * For example, I can penalize cells touching the boarder, or I can reward or penalize the number of cells alive (or not alive).\n",
    "* I am interested in the nature of chaotic functions given initial conditions, so I want to investigate how effective the agent is in controlling such a chaotic system given that the system is highly sensitive to its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods I will use are implementing the GOL system and building the reinforcement agent.\n",
    "\n",
    "The GOL agent, I will build myself. It will also be my means of collecting/generating data. \n",
    "\n",
    "The algorithm will be implemented by me, but it will be the same algorithm we used in class. I will implement the neural network myself so that I can use packages such as pytorch or tensorflow since they are very good for building ML models.\n",
    "\n",
    "Reward will be defined as cells touching the wall and defined by population size. The agent's actions are going to be either selecting a single cell to swap or selecting multiple cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Results\n",
    "\n",
    "Question: Can it prevent the cells from touching the wall?\n",
    "I don't think that it will perform very well. Q functions put values to states, so to some degree, it memorizes states. Given the nature of GOL, similar states have very different outcomes, so the Q function will do poorly when it comes to understanding the state of the board.\n",
    "\n",
    "Although, it may be a good search algorithm when the initial state of the board is repeated. Since it will keep seeing the same board states, it will learn them specifically very well. Over time, it can learn to prevent a lot of the wall touches that happen repeatedly.\n",
    "\n",
    "Question: Can it maximize the population?\n",
    "This one will probably perform poorly for the same reason as the last one, but it gets interesting if we consider the case where the agent can swap any number of cells at a generation. In that case, it can start from a completely blank board (blank boards require 3 cells to be turned on to continue surviving). In this case, it's interesting to investigate how it goes about optimizing the population. If it can learn at least a general sense, then it will probably converge to some solution where it creates a bunch of static objects which don't move (like 2x2 cubes everywhere). In that case, it may learn to avoid complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline\n",
    "\n",
    "* wk1 : build GOL and design Agent\n",
    "* wk2 : implement and experiment with agent's interactions with GOL\n",
    "* wk3 : collect interesting data to add to report\n",
    "* wk4 : compile and complete writeup of findings and interpretations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
