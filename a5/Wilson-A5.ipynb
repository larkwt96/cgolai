{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucas Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will write and apply code that trains neural networks of various numbers of hidden layers and units in each hidden layer and returns results as specified below.  You will do this once for a regression problem and once for a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralnetworks as nn\n",
    "import mlutils as ml\n",
    "\n",
    "from copy import deepcopy, copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNNs(X, T, trainFraction, hiddenLayerStructures, numberRepetitions, numberIterations, classify):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        * `X` is a matrix of input data of shape `nSamples x nFeatures`\n",
    "        * `T` is a matrix of target data of shape `nSamples x nOutputs`\n",
    "        * `trainFraction` is fraction of samples to use as training data. 1-`trainFraction` is number of samples for testing data\n",
    "        * `hiddenLayerStructures` is list of network architectures. For example, to test two networks, one with one hidden layer of 20 units, and one with 3 hidden layers with 5, 10, and 20 units in each layer, this argument would be `[[20], [5, 10, 20]]`.\n",
    "        * `numberRepetitions` is number of times to train a neural network. Calculate training and testing average performance (two separate averages) of this many training runs.\n",
    "        * `numberIterations` is the number of iterations to run the scaled conjugate gradient algorithm when a neural network is trained.\n",
    "        * `classify` is set to `True` if you are doing a classification problem, in which case `T` must be a single column of target class integers.\n",
    "\n",
    "    Returns:\n",
    "        `results` which is list with one element for each network structure tested. Each element is a list containing:\n",
    "            * the hidden layer structure (as a list),\n",
    "            * a list of training data performance for each repetition, \n",
    "            * a list of testing data performance for each repetition, and\n",
    "            * the number of seconds it took to run this many repetitions for this network structure.\n",
    "\n",
    "    Process:\n",
    "      * For each network structure given in `hiddenLayerStructures`\n",
    "        * For numberRepetitions\n",
    "          * Use `ml.partition` to randomly partition X and T into training and testing sets.\n",
    "          * Create a neural network of the given structure\n",
    "          * Train it for numberIterations\n",
    "          * Use the trained network to produce outputs for the training and for the testing sets\n",
    "          * If classifying, calculate the fraction of samples incorrectly classified for training and testing sets.\n",
    "           Otherwise, calculate the RMSE of training and testing sets.\n",
    "          * Add the training and testing performance to a collection (such as a list) for this network structure\n",
    "        * Add to a collection of all results the hidden layer structure, lists of training performance and testing performance, and seconds taken to do these repetitions.\n",
    "      * return the collection of all results\n",
    "    \"\"\"\n",
    "    # split test/train\n",
    "    trainX,trainT,testX,testT = ml.partition(X,T,(trainFraction,1-trainFraction),classification=classify)\n",
    "    results = []\n",
    "    for hiddenLayerStructure in hiddenLayerStructures:\n",
    "        resultsAppendage = [hiddenLayerStructure, [], [], 0]\n",
    "        startTime = time.time()\n",
    "        for _ in range(numberRepetitions):\n",
    "            nnet = nn.NeuralNetwork(X.shape[1], hiddenLayerStructure, T.shape[1])\n",
    "            nnet.train(trainX, trainT, numberIterations)\n",
    "            trainY = nnet.use(trainX)\n",
    "            testY = nnet.use(testX)\n",
    "            if classify:\n",
    "                trainPerformance = frac(trainT, trainY)\n",
    "                testPerformance = frac(testT, testY)\n",
    "            else:\n",
    "                trainPerformance = msqe(trainT, trainY)\n",
    "                testPerformance = msqe(trainT, trainY)\n",
    "            resultsAppendage[1].append(trainPerformance)\n",
    "            resultsAppendage[2].append(testPerformance)\n",
    "        resultsAppendage[3] = time.time() - startTime # now in seconds\n",
    "        results.append(resultsAppendage)\n",
    "    return results\n",
    "\n",
    "def msqe(T, Y)\n",
    "    return np.sqrt(np.mean((T-Y)**2))\n",
    "\n",
    "def frac(T, Y):\n",
    "    # calculate the fraction of samples incorrectly classified for training and testing sets\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    for t, y in zip(T, Y):\n",
    "        if t==y:\n",
    "            right+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    return wrong / (right + wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define MSQE as follows:\n",
    "Let $E = T - Y$ where $T$ is actual values, $Y$ is predicted by the model, and $E,T,Y \\epsilon \\mathbb{R}^{n\\times m}$\n",
    "\n",
    "$MSQE = \\sqrt{\\frac{||E||_2^2}{nm}}$ where $||â€¢||_2$ is $L_2$ matrix norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(results):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        The output of trainNNs()\n",
    "\n",
    "    Returns:\n",
    "        a list of lists like `results` but with the list of training performances\n",
    "        replaced by their mean and the list of testing performances replaced by\n",
    "        their mean.\n",
    "    \"\"\"\n",
    "    results = deepcopy(results)\n",
    "    for i,result in enumerate(results):\n",
    "        results[i] = result[0], np.mean(result[1]), np.mean(result[2]), result[3]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestNetwork(summary):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        The output of summarize\n",
    "        \n",
    "    Returns:\n",
    "        Returns the best element of `results`, determined by the element that has\n",
    "        the smallest test performance.\n",
    "    \"\"\"\n",
    "    best = 0\n",
    "    bestValue = np.inf\n",
    "    for i, result in enumerate(summary):\n",
    "        value = result[2]\n",
    "        if value < bestValue:\n",
    "            best = i\n",
    "            bestValue = value\n",
    "    return summary[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape((-1,1))\n",
    "T = X + 1 + np.random.uniform(-1, 1, ((10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, T, 'o-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71, 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.44, 0.43, 0.28,\n",
       "       0.25, 0.15, 0.15, 0.15, 0.15, 0.13, 0.12, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = nn.NeuralNetwork(X.shape[1], 2, T.shape[1])\n",
    "nnet.train(X, T, 100)\n",
    "nnet.getErrorTrace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70710678, 0.57309565, 0.57309565, 0.43163012, 0.24126546,\n",
       "       0.16374685, 0.12705871, 0.11678995, 0.07489894, 0.07442467,\n",
       "       0.07356634, 0.06805358, 0.06524633, 0.0635545 , 0.06066493,\n",
       "       0.05829651, 0.05817336, 0.05743338, 0.05733101, 0.05727533,\n",
       "       0.05724916, 0.05705867, 0.05701115, 0.05693773, 0.05690194,\n",
       "       0.05677163, 0.05649741, 0.05634835, 0.05628423, 0.05627231,\n",
       "       0.05626732, 0.05626253, 0.05624996, 0.05624851, 0.05623664,\n",
       "       0.05611664, 0.05608617, 0.05608337, 0.05607419, 0.05607215,\n",
       "       0.05607028, 0.05606607, 0.05605816, 0.05605428, 0.05605208,\n",
       "       0.05604483, 0.05604383, 0.05604105, 0.05603976, 0.05603731,\n",
       "       0.05603612, 0.05603408, 0.05603313, 0.05603174, 0.05603118,\n",
       "       0.0560302 , 0.05602982, 0.05602899, 0.05602867, 0.05602784,\n",
       "       0.05602749, 0.0560266 , 0.05602624, 0.05602542, 0.05602506,\n",
       "       0.05602442, 0.05602404, 0.05602359, 0.05602305, 0.05602266,\n",
       "       0.05602181, 0.05602134, 0.05602007, 0.05601951, 0.05601788,\n",
       "       0.05601727, 0.05601529, 0.05601447, 0.05601387, 0.05596463,\n",
       "       0.05593246, 0.05592979, 0.05592584, 0.05592093, 0.05592053,\n",
       "       0.05591982, 0.05591861, 0.05591836, 0.05591742, 0.05591425,\n",
       "       0.05591313, 0.05590686, 0.05588704, 0.05587857, 0.05585863,\n",
       "       0.05583902, 0.05582703, 0.05578944, 0.05569076, 0.05569039,\n",
       "       0.05568842])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = nn.NeuralNetwork(X.shape[1], [5, 5, 5], T.shape[1])\n",
    "nnet.train(X, T, 100)\n",
    "nnet.getErrorTrace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0466464 ],\n",
       "       [ 0.18826939],\n",
       "       [-0.2759482 ],\n",
       "       [ 0.0881317 ],\n",
       "       [ 0.11762717],\n",
       "       [-0.15674088],\n",
       "       [ 0.27939634],\n",
       "       [-0.42492736],\n",
       "       [ 0.32692532],\n",
       "       [-0.09335799]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = nnet.use(X)\n",
    "np.sqrt((Y-T)**2)\n",
    "Y-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2,\n",
       "  [0.2194713258263557,\n",
       "   0.2114095714985508,\n",
       "   0.22274715335941345,\n",
       "   0.2227996106190234,\n",
       "   0.22538059607592936],\n",
       "  [0.35578212958562017,\n",
       "   0.5471097371212502,\n",
       "   0.3293095892741292,\n",
       "   0.33108550016827787,\n",
       "   0.3264035525050801],\n",
       "  0.14601969718933105],\n",
       " [10,\n",
       "  [0.09737985028760267,\n",
       "   0.20359267098049927,\n",
       "   0.18984175932892755,\n",
       "   0.19473738471764884,\n",
       "   0.15328914078006337],\n",
       "  [1.081646185211485,\n",
       "   0.42372654880573324,\n",
       "   0.44779456211306584,\n",
       "   0.419172796385056,\n",
       "   0.667377209656179],\n",
       "  0.10531091690063477],\n",
       " [[10, 10],\n",
       "  [0.18563886693410858,\n",
       "   0.2132182479268321,\n",
       "   0.1272122271397655,\n",
       "   0.18245430026252607,\n",
       "   0.0823915155723054],\n",
       "  [0.5034337072293381,\n",
       "   0.4078126692979338,\n",
       "   0.79027132259832,\n",
       "   0.6856635825746842,\n",
       "   1.1897997384771848],\n",
       "  0.1346449851989746]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainNNs(X, T, 0.8, [2, 10, [10, 10]], 5, 100, classify=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainNNs(X, T, 0.8, [0, 1, 2, 10, [10, 10], [5, 5, 5, 5], [2]*5], 50, 100, classify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.38801431490062305, 0.7751956676656273, 0.026372194290161133),\n",
       " (1, 0.23819926337062783, 0.3101722025301149, 0.9555912017822266),\n",
       " (2, 0.19052123800422358, 0.5380342485530495, 0.9629521369934082),\n",
       " (10, 0.172407092396284, 0.6375270325821818, 0.9033830165863037),\n",
       " ([10, 10], 0.17114145671898817, 0.6650026043422542, 1.1804962158203125),\n",
       " ([5, 5, 5, 5], 0.19063665127215235, 0.5173539783231983, 1.7652430534362793),\n",
       " ([2, 2, 2, 2, 2], 0.21725590782674886, 0.390199927287506, 1.8850581645965576)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.23819926337062783, 0.3101722025301149, 0.9555912017822266)\n",
      "Hidden Layers 1 Average RMSE Training 0.24 Testing 0.31 Took 0.96 seconds\n"
     ]
    }
   ],
   "source": [
    "best = bestNetwork(summarize(results))\n",
    "print(best)\n",
    "print('Hidden Layers {} Average RMSE Training {:.2f} Testing {:.2f} Took {:.2f} seconds'.format(*best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hummm...neural nets with no hidden layers did best on this simple data set.  Why?  Remember what \"best\" means.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "The reason a neural network without hidden layers performs better than more complex ones is because..\n",
    "\n",
    "1. A neural network without hidden layers is just linear and the actual function is linear, so naturally, the best model for a function is itself. That's why a no hidden layer neural network performs well.\n",
    "2. Since there are no hidden layers, it can't over-fit to the training data since it's not complex enough. However, the more complex models which do over-fit fit to the noise added, so they fail to perform well on testing data since the learned noise is useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Regression Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc -q http://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeQuotes(word):\n",
    "    return word[1:-1]\n",
    "cols = tuple(range(1, 27))\n",
    "colConverter = {}\n",
    "for col in cols:\n",
    "    colConverter[col] = removeQuotes\n",
    "names = list(np.loadtxt('energydata_complete.csv', dtype=str, delimiter=\",\", usecols=cols, converters=colConverter)[0])\n",
    "data = np.loadtxt('energydata_complete.csv', delimiter=\",\", skiprows=1, usecols=cols, converters=colConverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lights', 'T1', 'RH_1', 'T2']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[1:5] # just some cuz space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19735, 26)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19735, 24), (19735, 2))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xenergy, Xnames = data[:,2:], names[2:]\n",
    "Tenergy, Tnames = data[:,:2], names[:2]\n",
    "\n",
    "Xenergy.shape, Tenergy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['RH_2', 'T3'], ['Appliances', 'lights'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnames[3:5], Tnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis to determine number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFraction = 0.8\n",
    "trainX,trainT,testX,testT = ml.partition(Xenergy,Tenergy,(trainFraction,1-trainFraction),classification=False)\n",
    "nnet = nn.NeuralNetwork(Xenergy.shape[1], [10, 10], Tenergy.shape[1])\n",
    "nnet.train(trainX, trainT, 3000)\n",
    "plt.plot(nnet.getErrorTrace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error levels off around 400 but continues to decrease slightly. We'll make the cutoff around 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/A5grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m netsEnergy = [0, 5, [5, 5], [10, 10], [5, 5, 5],\n\u001b[1;32m      2\u001b[0m               [10, 10, 10], [5, 5, 5, 5], [2, 2, 2, 2, 2, 2], [20, 20], 100]\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainNNs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXenergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTenergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetsEnergy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/A5grader.py\u001b[0m in \u001b[0;36mtrainNNs\u001b[0;34m(X, T, trainFraction, hiddenLayerStructures, numberRepetitions, numberIterations, classify)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberRepetitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenLayerStructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, T, nIterations, verbose, weightPrecision, errorPrecision)\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0mnIterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnIterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                             ftracep=True)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscgresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/scaledconjugategradient.py\u001b[0m in \u001b[0;36mscg\u001b[0;34m(x, f, gradf, *fargs, **params)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mgradold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mgradnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;31m## If the gradient is zero then we are done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradnew\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36mgradF\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mdVs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdVs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36m_backward_pass\u001b[0;34m(self, delta, Z)\u001b[0m\n\u001b[1;32m    137\u001b[0m                                  np.dot( Z[Zi-1].T, delta)))\n\u001b[1;32m    138\u001b[0m                 \u001b[0mdVs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdVs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "netsEnergy = [0, 5, [5, 5], [10, 10], [5, 5, 5],\n",
    "              [10, 10, 10], [5, 5, 5, 5], [2, 2, 2, 2, 2, 2], [20, 20], 100]\n",
    "results = trainNNs(Xenergy, Tenergy, 0.8, netsEnergy, 10, 700, classify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = bestNetwork(summarize(results))\n",
    "print(best)\n",
    "print('Hidden Layers {} Average RMSE Training {:.2f} Testing {:.2f} Took {:.2f} seconds'.format(*best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that large numbers of layers tends to over-fit the data. Due to its complexity, it's capable of memorizing some of the data, so when we test it on testing data, it performs poorly because it is using what it's stored not what it's generalized.\n",
    "\n",
    "We can see that this is what it is doing when our training accuracy is much higher than our testing accuracy. Typically, we want to identify where testing accuracy stops lowering and starts rising. That threshold  is where the model begins to over-fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train another network with your best hidden layer structure on 0.8 of the data and use the trained network on the testing data (the remaining 0.2 of the date).  As before use `ml.partition` to produce the training and testing sets.\n",
    "\n",
    "For the testing data, plot the predicted and actual `Appliances` energy use, and the predicted and actual `lights` energy use, in two separate plots.  Discuss what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Classification Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Anuran Calls (MFCCs).zip\r\n",
      "  inflating: Frogs_MFCCs.csv         \r\n",
      "  inflating: Readme.txt              \r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc -q 'http://archive.ics.uci.edu/ml/machine-learning-databases/00406/Anuran Calls (MFCCs).zip'\n",
    "![ -f Frogs_MFCCs.csv ] || unzip Anuran*zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Frogs_MFCCs.csv')\n",
    "names = list(df.columns)\n",
    "data = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesIndex = names.index('Species')\n",
    "Xanuran, Tanuran = np.array(data[:,:-4], dtype=np.float64), data[:,speciesIndex]\n",
    "speciesMap = list(np.unique(Tanuran))\n",
    "Tanuran = np.array(list(map(lambda species:speciesMap.index(species), Tanuran)))\n",
    "Tanuran = Tanuran.reshape((Tanuran.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7195, 22), (7195, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xanuran.shape, Tanuran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672 samples in class 0\n",
      "3478 samples in class 1\n",
      "542 samples in class 2\n",
      "310 samples in class 3\n",
      "472 samples in class 4\n",
      "1121 samples in class 5\n",
      "270 samples in class 6\n",
      "114 samples in class 7\n",
      "68 samples in class 8\n",
      "148 samples in class 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('{} samples in class {}'.format(np.sum(Tanuran==i), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/A5grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXanuran\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTanuran\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainFraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrainFraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXanuran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTanuran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetErrorTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, T, nIterations, verbose, weightPrecision, errorPrecision)\u001b[0m\n\u001b[1;32m     81\u001b[0m                             \u001b[0mnIterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnIterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                             ftracep=True)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscgresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/scaledconjugategradient.py\u001b[0m in \u001b[0;36mscg\u001b[0;34m(x, f, gradf, *fargs, **params)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mgradold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mgradnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;31m## If the gradient is zero then we are done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradnew\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36mgradF\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgradF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdVs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/pass/f/doc/school/files/y4/s1/c440/a5/neuralnetworks.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mZprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZprev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0mZs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainFraction = 0.8\n",
    "trainX,trainT,testX,testT = ml.partition(Xanuran,Tanuran,(trainFraction,1-trainFraction),classification=False)\n",
    "nnet = nn.NeuralNetwork(Xanuran.shape[1], [10, 10], Tanuran.shape[1])\n",
    "nnet.train(trainX, trainT, 3000)\n",
    "plt.plot(nnet.getErrorTrace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netsAnuran = [0, 5, [5, 5], [10, 10], [5, 5, 5],\n",
    "              [10, 10, 10], [5, 5, 5, 5], [2, 2, 2, 2, 2, 2], [20, 20], 100]\n",
    "results = trainNNs(Xanuran, Tanuran, 0.8, netsAnuran, 10, 700, classify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.0, 1.0, 0.23218512535095215),\n",
       " (5, 1.0, 1.0, 2.1535329818725586),\n",
       " ([5, 5], 1.0, 1.0, 3.467493772506714)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.0, 1.0, 0.23218512535095215)\n",
      "Hidden Layers 0 Average RMSE Training 1.00 Testing 1.00 Took 0.23 seconds\n"
     ]
    }
   ],
   "source": [
    "best = bestNetwork(summarize(results))\n",
    "print(best)\n",
    "print('Hidden Layers {} Average RMSE Training {:.2f} Testing {:.2f} Took {:.2f} seconds'.format(*best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do an investigation like you did for the regression data. \n",
    "\n",
    "Test at least 10 different hidden layer structures. Then train another network with your best hidden layer structure on 0.8 of the data and use the trained network on the testing data (the remaining 0.2 of the date). \n",
    "\n",
    "Plot the predicted and actual `Species` for the testing data as an integer.  Discuss what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Download [A5grader.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/A5grader.tar) and extract `A5grader.py` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'Wilson-A5.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "\n",
      "Testing summarize([[[1,1], [1.2, 1.3, 1.4], [2.2, 2.3, 2.4], 0.5], [[2,2,2], [4.4, 4.3, 4.2], [6.5, 6.4, 6.3], 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [([1, 1], 1.3, 2.3000000000000003, 0.5), ([2, 2, 2], 4.3, 6.3999999999999995, 0.6)]\n",
      "\n",
      "Testing bestNetwork([[[1, 1], 1.3, 2.3, 0.5], [[2, 2, 2], 4.3, 1.3, 0.6]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[2, 2, 2], 4.3, 1.3, 0.6]\n",
      "\n",
      "X = np.random.uniform(-1, 1, (100, 3))\n",
      "T = np.hstack(((X**2 - 0.2*X**3).sum(axis=1,keepdims=True),\n",
      "               (np.sin(X)).sum(axis=1,keepdims=True)))\n",
      "result = trainNNs(X, T, 0.7, [0, 5, 10, [20, 20]], 10, 100, False)\n",
      "\n",
      "--- 20/20 points. Correct.\n",
      "\n",
      "Testing bestNetwork(summarize(result))\n",
      "\n",
      "--- 20/20 points. You correctly found that network [20, 20] is best.\n",
      "\n",
      "a5 Execution Grade is 60 / 60\n",
      "\n",
      "======================= The regression data set =======================\n",
      "\n",
      "--- _ / 5 points. Read the data in energydata_complete.csv into variables Xenergy and Tenergy.\n",
      "\n",
      "--- _ / 5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _ / 5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _ / 5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual Appliances energy use, and the predicted and actual lights energy use, in two separate plots. Discuss what you see.\n",
      "\n",
      "======================= Classification data set =======================\n",
      "\n",
      "--- _ / 5 points. Read the data in Frogs_MFCCs.csv into variables Xanuran and Tanuran.\n",
      "\n",
      "--- _ / 5 points. Train some networks by calling the NeuralNetwork constructor and train method and plot the error trace to help you decide now many iterations might be needed.\n",
      "\n",
      "--- _ / 5 points. Try at least 10 different hidden layer structures using trainNNs.\n",
      "\n",
      "--- _ / 5 points. Train another network with your best hidden layer structure on 0.8 of the data and test it on remaining 0.2 of the data. Plot the predicted and actual class labels. Discuss what you see.\n",
      "\n",
      "a5 Notebook Grade is   / 40\n",
      "\n",
      "a5 FINAL GRADE is  / 100\n",
      "\n",
      "\n",
      "a5 EXTRA CREDIT is  / 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i \"A5grader.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not include this section in your notebook.\n",
    "\n",
    "Name your notebook ```Lastname-A5.ipynb```.  So, for me it would be ```Anderson-A5.ipynb```.  Submit the file using the ```Assignment 5``` link on [Canvas](https://colostate.instructure.com/courses/68135)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "  2. Repeat the above regression and classification experiments with a second regression data set and a second classification data set.\n",
    "  \n",
    "  2. Since you are collecting the performance of all repetitions for each network structure, you can calculate a confidence interval about the mean, to help judge significant differences. Do this for either the regression or the classification data and plot the mean test performance with confidence intervals for each network structure tested.  Discuss the statistical significance of the differences among the means.  One website I found to help with this is the site [Correct way to obtain confidence interval with scipy](https://stackoverflow.com/questions/28242593/correct-way-to-obtain-confidence-interval-with-scipy).\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
